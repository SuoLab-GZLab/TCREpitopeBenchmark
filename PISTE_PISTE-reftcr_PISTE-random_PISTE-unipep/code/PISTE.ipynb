{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf5f971-8c55-44dd-b0d8-1d44d808fe9f",
   "metadata": {},
   "source": [
    "# 1.Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d10e4a-4fa0-487d-ab53-5d4177fba5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from Model.PISTE import Transformer\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "random.seed(1234)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pep_max_len = 15\n",
    "hla_max_len = 34\n",
    "tcr_max_len = 30\n",
    "tgt_len = pep_max_len + hla_max_len + tcr_max_len\n",
    "\n",
    "batch_size = 1024\n",
    "# epochs = 60\n",
    "threshold = 0.5\n",
    "d_model = 64\n",
    "dim = 64\n",
    "d_ff = 512\n",
    "e_layers = 3\n",
    "n_heads = 9\n",
    "sigma = 1\n",
    "d_layers = 1\n",
    "interact_layers = 1\n",
    "window_size = '3'\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:1\" if use_cuda else \"cpu\")\n",
    "vocab = {'C': 1, 'W': 2, 'V': 3, 'A': 4, 'H': 5, 'T': 6, 'E': 7, 'K': 8, 'N': 9, 'P': 10, 'I': 11, 'L': 12, 'S': 13, 'D': 14, 'G': 15, 'Q': 16, 'R': 17, 'Y': 18, 'F': 19, 'M': 20, '-': 0}\n",
    "vocab_size = len(vocab)\n",
    "f_mean = lambda l: sum(l) / len(l)\n",
    "\n",
    "def read_predict_data(predict_data, antigen_type, batch_size):\n",
    "    \n",
    "    column_names = predict_data.columns\n",
    "    if \"HLA_sequence\" not in column_names:\n",
    "    \n",
    "        hla_sequence = pd.read_csv(r'../data/raw_data/common_hla_sequence.csv')\n",
    "        predict_data = pd.merge(predict_data, hla_sequence, on = 'HLA_type')\n",
    "        \n",
    "    pep_inputs, hla_inputs, tcr_inputs = make_data(predict_data, antigen_type)\n",
    "    loader = Data.DataLoader(MyDataSet(pep_inputs, hla_inputs, tcr_inputs), batch_size, shuffle=False, num_workers=0)\n",
    "    return predict_data, pep_inputs, hla_inputs, tcr_inputs, loader\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, pep_inputs, hla_inputs, tcr_inputs):\n",
    "        super(MyDataSet, self).__init__()\n",
    "        self.pep_inputs = pep_inputs\n",
    "        self.hla_inputs = hla_inputs\n",
    "        self.tcr_inputs = tcr_inputs\n",
    "\n",
    "#\n",
    "    def __len__(self):\n",
    "        return self.pep_inputs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pep_inputs[idx], self.hla_inputs[idx], self.tcr_inputs[idx]\n",
    "\n",
    "\n",
    "\n",
    "class WeightedFocalLoss(nn.Module):\n",
    "    \"Non weighted version of Focal Loss\"\n",
    "\n",
    "    def __init__(self, alpha=.25, gamma=2):\n",
    "        super(WeightedFocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor([alpha, 1 - alpha]).to(device)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        targets = targets.type(torch.long)\n",
    "        at = self.alpha.gather(0, targets.data.view(-1))\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = at * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "\n",
    "def make_data(data, type):\n",
    "    pep_inputs, hla_inputs, tcr_inputs = [], [], []\n",
    "    num = 0\n",
    "    \n",
    "    if type == 'WT':\n",
    "        for pep, hla, tcr in zip(data.WT_pep, data.HLA_sequence, data.CDR3):\n",
    "            pep, hla, tcr = pep.ljust(pep_max_len, '-'), hla.ljust(hla_max_len, '-'), tcr.ljust(tcr_max_len, '-')\n",
    "\n",
    "            pep_input = [[vocab[n] for n in pep]]\n",
    "            hla_input = [[vocab[n] for n in hla]]\n",
    "            tcr_input = [[vocab[n] for n in tcr]]\n",
    "            pep_inputs.extend(pep_input)\n",
    "            hla_inputs.extend(hla_input)\n",
    "            tcr_inputs.extend(tcr_input)\n",
    "            \n",
    "            num = num + 1\n",
    "            \n",
    "    else:\n",
    "        for pep, hla, tcr in zip(data.MT_pep, data.HLA_sequence, data.CDR3):\n",
    "            pep, hla, tcr = pep.ljust(pep_max_len, '-'), hla.ljust(hla_max_len, '-'), tcr.ljust(tcr_max_len, '-')\n",
    "\n",
    "            pep_input = [[vocab[n] for n in pep]]\n",
    "            hla_input = [[vocab[n] for n in hla]]\n",
    "            tcr_input = [[vocab[n] for n in tcr]]\n",
    "            pep_inputs.extend(pep_input)\n",
    "            hla_inputs.extend(hla_input)\n",
    "            tcr_inputs.extend(tcr_input)\n",
    "            \n",
    "            num = num + 1\n",
    "    \n",
    "\n",
    "    return torch.LongTensor(pep_inputs), torch.LongTensor(hla_inputs), torch.LongTensor(tcr_inputs)\n",
    "\n",
    "\n",
    "def transfer(y_prob, threshold=0.5):\n",
    "    return np.array([[0, 1][x > threshold] for x in y_prob])\n",
    "\n",
    "\n",
    "def eval_step(model, val_loader, threshold = 0.5, use_cuda = False):\n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    torch.manual_seed(19961231)\n",
    "    torch.cuda.manual_seed(19961231)\n",
    "    with torch.no_grad():\n",
    "        y_prob_val_list, dec_attns_val_list = [], []\n",
    "        for val_pep_inputs, val_hla_inputs, val_tcr_inputs in val_loader:\n",
    "            val_pep_inputs, val_hla_inputs, val_tcr_inputs = val_pep_inputs.to(device), val_hla_inputs.to(device), val_tcr_inputs.to(device)\n",
    "            \n",
    "            val_outputs, _, val_dec_self_attns = model(val_pep_inputs, val_hla_inputs, val_tcr_inputs)\n",
    "            \n",
    "            y_prob_val = nn.Softmax(dim=1)(val_outputs)[:, 1].cpu().detach().numpy()\n",
    "            y_prob_val_list.extend(y_prob_val)\n",
    "            \n",
    "            dec_attns_val_list.extend(val_dec_self_attns[0][:, :, 15:, :15]) \n",
    "                    \n",
    "        y_pred_val_list = transfer(y_prob_val_list, threshold)\n",
    "    \n",
    "    return y_pred_val_list, y_prob_val_list, dec_attns_val_list\n",
    "\n",
    "\n",
    "def fix(data_ori):\n",
    "    data=pd.read_csv(data_ori)\n",
    "    # data = data[data['MHC'].str.contains(r'\\*', na=False)]#换成自己的数据时要加这一行\n",
    "    data.reset_index(drop=True)\n",
    "    #'CDR3.beta', 'antigen_epitope','mhc.a','label','negative.source','license'\n",
    "    data.rename(columns={'CDR3B':'CDR3','Epitope':'MT_pep','MHC':'HLA_type','Affinity':'Label','HLA_seq':'HLA_sequence'},inplace=True)\n",
    "    df=data[['CDR3', 'MT_pep','HLA_type','HLA_sequence','Label']]\n",
    "    # df['HLA_sequence']=[]#需要HLAsequence\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    df.to_csv(data_new,index=False)\n",
    "def Original_model_prediction(_input, modelfile_path, _output, antigen_type='WT'):\n",
    "    # parser = argparse.ArgumentParser(usage = 'TCR-ANTIGEN-HLA binding prediction')\n",
    "    # parser.add_argument('--input', type = str, help = 'the path to the input data file (*.csv).')\n",
    "    # parser.add_argument(\"--model_name\", default='random', type=str, choices=['random', 'unipep', 'reftcr'],\n",
    "    #                         help=\"Choose different trained model by using datasets generated by different negative datasampling.\")\n",
    "    # parser.add_argument('--threshold', type = float, default = 0.5, help = 'the threshold to define predicted binder, float from 0 - 1, the recommended value is 0.5')\n",
    "    # parser.add_argument('--antigen_type', type = str, default = 'MT', help = 'the antigen type, choice[\"MT\",\"WT\"]')\n",
    "    # parser.add_argument('--output', type = str, help = 'The directory where the output results are stored(*.csv).')\n",
    "    # args = parser.parse_args()\n",
    "      \n",
    "    # errLogPath = _output + '/error.log'\n",
    "    # if not os.path.exists(_output): os.makedirs(_output)\n",
    "        \n",
    "    # antigen_type = _antigen_type\n",
    "    predict_data = fix(_input)\n",
    "    \n",
    "    \n",
    "    predict_data, predict_pep_inputs, predict_hla_inputs, predict_tcr_inputs,predict_loader = read_predict_data(predict_data, antigen_type, batch_size)\n",
    "    \n",
    "    \n",
    "    model = Transformer(device=device,\n",
    "                        vocab_size=vocab_size,\n",
    "                        d_model=d_model,\n",
    "                        e_layers=e_layers,\n",
    "                        d=dim,\n",
    "                        n_heads=n_heads,\n",
    "                        sigma=sigma,\n",
    "                        window_threshold=window_size,\n",
    "                        d_ff=d_ff,\n",
    "                        interact_layers=interact_layers,\n",
    "                        tgt_len=tgt_len,\n",
    "                        hla_max_len=hla_max_len,\n",
    "                        d_layers=d_layers).to(device)\n",
    "    criterion = WeightedFocalLoss(alpha=.75)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    model.load_state_dict(torch.load(modelfile_path, map_location='cpu'))\n",
    "    model_eval = model.eval()\n",
    "    \n",
    "    y_pred, y_prob, attns = eval_step(model_eval, predict_loader, 0.5, use_cuda)\n",
    "    \n",
    "    predict_data['y_pred'], predict_data['y_prob'] = y_pred, y_prob\n",
    "    predict_data.rename(columns={'Label':'y_true'},inplace=True)\n",
    "    \n",
    "    predict_data.to_csv(f'{_output}probability.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e2dae-9a46-4c6d-9543-8dcdaa84b5b3",
   "metadata": {},
   "source": [
    "# PISTE_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce2c42e-d6e5-4ef5-854f-1ac108e78e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../../data/test_CDR3B_others.csv\"\n",
    "modelfile_path=\"../../Original_model/PISTE_random.pkl\"\n",
    "result_path=\"../../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path, antigen_type='MT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6f59b-ec5a-49bd-9b5d-567919c08e8b",
   "metadata": {},
   "source": [
    "# PISTE_unipep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eedf776-cdbd-4b7c-8f0a-6ed2be14c5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../../data/test_CDR3B_others.csv\"\n",
    "modelfile_path=\"../../Original_model/PISTE_unipep.pkl\"\n",
    "result_path=\"../../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path, antigen_type='MT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623a73d-0df4-45e7-807c-53daf08a38af",
   "metadata": {},
   "source": [
    "# PISTE_reftcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5d4ed-b736-4d7a-832b-9265464164db",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../../data/test_CDR3B_others.csv\"\n",
    "modelfile_path=\"../../Original_model/PISTE_reftcr.pkl\"\n",
    "result_path=\"../../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path, antigen_type='MT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCREpi(piste)",
   "language": "python",
   "name": "piste1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
