{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f9043e",
   "metadata": {},
   "source": [
    "# 1.Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0e3061-f6ca-4434-a6ec-287fde94d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./vittcr/orig/code')\n",
    "from TcrPepTransform_utils import DropPath, trunc_normal_, lecun_normal_\n",
    "from TcrPepTransform_beta import *\n",
    "from utils_train_new import *\n",
    "import torch\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import joblib\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Optimized function to process the input file and return a dictionary\n",
    "def process_file_return_dict(inpath, length_cdr3=20, length_pep=15, chain='beta'):\n",
    "    Atchley = {\n",
    "        'A': np.array((-0.591, -1.302, -0.733, 1.57, -0.146)),\n",
    "        'C': np.array((-1.343, 0.465, -0.862, -1.02, -0.255)),\n",
    "        'D': np.array((1.05, 0.302, -3.656, -0.259, -3.242)),\n",
    "        'E': np.array((1.357, -1.453, 1.477, 0.113, -0.837)),\n",
    "        'F': np.array((-1.006, -0.59, 1.891, -0.397, 0.412)),\n",
    "        'G': np.array((-0.384, 1.652, 1.33, 1.045, 2.064)),\n",
    "        'H': np.array((0.336, -0.417, -1.673, -1.474, -0.078)),\n",
    "        'I': np.array((-1.239, -0.547, 2.131, 0.393, 0.816)),\n",
    "        'K': np.array((1.831, -0.561, 0.533, -0.277, 1.648)),\n",
    "        'L': np.array((-1.019, -0.987, -1.505, 1.266, -0.912)),\n",
    "        'M': np.array((-0.663, -1.524, 2.219, -1.005, 1.212)),\n",
    "        'N': np.array((0.945, 0.828, 1.299, -0.169, 0.933)),\n",
    "        'P': np.array((0.189, 2.081, -1.628, 0.421, -1.392)),\n",
    "        'Q': np.array((0.931, -0.179, -3.005, -0.503, -1.853)),\n",
    "        'R': np.array((1.538, -0.055, 1.502, 0.44, 2.897)),\n",
    "        'S': np.array((-0.228, 1.399, -4.76, 0.67, -2.647)),\n",
    "        'T': np.array((-0.032, 0.326, 2.213, 0.908, 1.313)),\n",
    "        'V': np.array((-1.337, -0.279, -0.544, 1.242, -1.262)),\n",
    "        'W': np.array((-0.595, 0.009, 0.672, -2.128, -0.184)),\n",
    "        'Y': np.array((0.26, 0.83, 3.097, -0.838, 1.512))\n",
    "    }\n",
    "    \n",
    "    def generate_interaction_map_optimized(df, query, length_cdr3, length_pep, chain):\n",
    "        features = list(query.columns)\n",
    "        dict_combined = defaultdict(list)\n",
    "        dict_intermap = defaultdict(list)\n",
    "\n",
    "        # Prepare CDR3 and peptide sequences\n",
    "        if chain == \"beta\":\n",
    "            cdr3s = df['cdr3b'].str.upper().tolist()\n",
    "        elif chain == \"alpha\":\n",
    "            cdr3s = df['cdr3a'].str.upper().tolist()\n",
    "        peptides = df['peptide'].str.upper().tolist()\n",
    "\n",
    "        if 'Binding' in df.columns:\n",
    "            Bindings = df['Binding'].tolist()\n",
    "\n",
    "        # Precompute Atchley values for sequences\n",
    "        atchley_matrix_cdr3 = np.zeros((len(cdr3s), length_cdr3, len(features)))\n",
    "        atchley_matrix_peptide = np.zeros((len(peptides), length_pep, len(features)))\n",
    "\n",
    "        for i, cdr3 in enumerate(cdr3s):\n",
    "            for j, char in enumerate(cdr3[:length_cdr3]):\n",
    "                if char in query.index:\n",
    "                    atchley_matrix_cdr3[i, j, :] = query.loc[char].values\n",
    "\n",
    "        for i, peptide in enumerate(peptides):\n",
    "            for j, char in enumerate(peptide[:length_pep]):\n",
    "                if char in query.index:\n",
    "                    atchley_matrix_peptide[i, j, :] = query.loc[char].values\n",
    "\n",
    "        # Compute interaction maps for each feature\n",
    "        for order, feature in enumerate(features):\n",
    "            feature_cdr3 = atchley_matrix_cdr3[:, :, order]\n",
    "            feature_peptide = atchley_matrix_peptide[:, :, order]\n",
    "            intermap = np.abs(feature_cdr3[:, :, None] - feature_peptide[:, None, :])\n",
    "            dict_intermap[feature] = intermap\n",
    "\n",
    "        # Save the combined interaction maps\n",
    "        combinedmap = np.stack([dict_intermap[feature] for feature in features], axis=1)\n",
    "        if chain == 'alpha':\n",
    "            dict_combined['combined_map_alpha'] = combinedmap.tolist()\n",
    "        elif chain == 'beta':\n",
    "            dict_combined['combined_map_beta'] = combinedmap.tolist()\n",
    "\n",
    "        dict_combined['cdr3'] = cdr3s\n",
    "        dict_combined['peptide'] = peptides\n",
    "        if 'Binding' in df.columns:\n",
    "            dict_combined['Binding'] = Bindings\n",
    "\n",
    "        return dict_combined\n",
    "\n",
    "    queryfile = pd.DataFrame(Atchley).T\n",
    "    queryfile.columns = ['f1', 'f2', 'f3', 'f4', 'f5']\n",
    "\n",
    "    data = pd.read_csv(inpath)\n",
    "    data.rename(columns={'CDR3B': 'cdr3b', 'Epitope': 'peptide', 'Affinity': 'Binding'}, inplace=True)\n",
    "    data = data[['cdr3b', 'peptide', 'Binding']]\n",
    "\n",
    "    dict_combined = generate_interaction_map_optimized(\n",
    "        df=data,\n",
    "        query=queryfile,\n",
    "        length_cdr3=length_cdr3,\n",
    "        length_pep=length_pep,\n",
    "        chain=chain )\n",
    "    return dict_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b45f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Original_model_prediction(testfile, save_model_path, resultfile_path, chain='beta'):\n",
    "    setup_seed(1234)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = TcrPepTransform_single(\n",
    "        input_height=20, \n",
    "        input_width=15, \n",
    "        in_chans=5, \n",
    "        patch_size=4, \n",
    "        num_classes=2, \n",
    "        embed_dim=256, \n",
    "        depth=1, \n",
    "        num_heads=4, \n",
    "        mlp_ratio=4, \n",
    "        qkv_bias=True, \n",
    "        drop_rate=0.1, \n",
    "        attn_drop_rate=0.05, \n",
    "        drop_path_rate=0, \n",
    "        act_layer=torch.nn.GELU)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    model.acc_func = metrics.accuracy_score\n",
    "    model.auc_roc_func = metrics.roc_auc_score\n",
    "    model.auc_pr_func = pr_auc_score\n",
    "    model.f1_score_func = metrics.f1_score\n",
    "    model.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    " \n",
    "    test_dicts = process_file_return_dict(testfile, chain=chain)\n",
    "    label_valid = np.array(test_dicts['Binding'])\n",
    "    label_valid_initialized = Labels_Initialization(num_classes=2, labels=label_valid)\n",
    "\n",
    "    if chain == 'beta':\n",
    "        data_valid = np.array(test_dicts['combined_map_beta'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    elif chain == 'alpha':\n",
    "        data_valid = np.array(test_dicts['combined_map_alpha'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid chain type. Must be 'alpha' or 'beta'.\")\n",
    "\n",
    "    data_valid = torch.from_numpy(data_valid)\n",
    "    dataset_valid = MyDataset(data=data_valid, labl=label_valid_initialized, raw_cdr3=raw_cdr3_test, raw_epitope=raw_epitope_test)\n",
    "    dl_valid = DataLoader(dataset_valid, batch_size=len(data_valid), shuffle=False, num_workers=5)\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    model.eval()\n",
    "    dfhistory = eval_model(\n",
    "        model_initial=model,\n",
    "        dl_valid=dl_valid,\n",
    "        device=device)\n",
    "    dfhistory.to_csv(resultfile_path + '_probability.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259bbf56-525d-4b19-8f8f-882886e2acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/test.csv\"\n",
    "modelfile_path=\"../Original_model/VitTCR.pt\"\n",
    "result_path=\"../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3c638-72dc-41db-a0e9-3bda6b740764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82275a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e789d1b7-3945-4891-848b-4d547fbdaa03",
   "metadata": {},
   "source": [
    "# 2.Model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "465189a7-8089-44f8-83c4-4f9e9ef2f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/bingxing2/home/scx6666/zhengli/VitTCR/vittcr/orig/code')\n",
    "from TcrPepTransform_utils import DropPath, trunc_normal_, lecun_normal_\n",
    "from TcrPepTransform_beta import *\n",
    "from utils_train_new import *\n",
    "import torch\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import joblib\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Optimized function to process the input file and return a dictionary\n",
    "def process_file_return_dict(inpath, length_cdr3=20, length_pep=15, chain='beta'):\n",
    "    Atchley = {\n",
    "        'A': np.array((-0.591, -1.302, -0.733, 1.57, -0.146)),\n",
    "        'C': np.array((-1.343, 0.465, -0.862, -1.02, -0.255)),\n",
    "        'D': np.array((1.05, 0.302, -3.656, -0.259, -3.242)),\n",
    "        'E': np.array((1.357, -1.453, 1.477, 0.113, -0.837)),\n",
    "        'F': np.array((-1.006, -0.59, 1.891, -0.397, 0.412)),\n",
    "        'G': np.array((-0.384, 1.652, 1.33, 1.045, 2.064)),\n",
    "        'H': np.array((0.336, -0.417, -1.673, -1.474, -0.078)),\n",
    "        'I': np.array((-1.239, -0.547, 2.131, 0.393, 0.816)),\n",
    "        'K': np.array((1.831, -0.561, 0.533, -0.277, 1.648)),\n",
    "        'L': np.array((-1.019, -0.987, -1.505, 1.266, -0.912)),\n",
    "        'M': np.array((-0.663, -1.524, 2.219, -1.005, 1.212)),\n",
    "        'N': np.array((0.945, 0.828, 1.299, -0.169, 0.933)),\n",
    "        'P': np.array((0.189, 2.081, -1.628, 0.421, -1.392)),\n",
    "        'Q': np.array((0.931, -0.179, -3.005, -0.503, -1.853)),\n",
    "        'R': np.array((1.538, -0.055, 1.502, 0.44, 2.897)),\n",
    "        'S': np.array((-0.228, 1.399, -4.76, 0.67, -2.647)),\n",
    "        'T': np.array((-0.032, 0.326, 2.213, 0.908, 1.313)),\n",
    "        'V': np.array((-1.337, -0.279, -0.544, 1.242, -1.262)),\n",
    "        'W': np.array((-0.595, 0.009, 0.672, -2.128, -0.184)),\n",
    "        'Y': np.array((0.26, 0.83, 3.097, -0.838, 1.512))\n",
    "    }\n",
    "    \n",
    "    def generate_interaction_map_optimized(df, query, length_cdr3, length_pep, chain):\n",
    "        features = list(query.columns)\n",
    "        dict_combined = defaultdict(list)\n",
    "        dict_intermap = defaultdict(list)\n",
    "\n",
    "        # Prepare CDR3 and peptide sequences\n",
    "        if chain == \"beta\":\n",
    "            cdr3s = df['cdr3b'].str.upper().tolist()\n",
    "        elif chain == \"alpha\":\n",
    "            cdr3s = df['cdr3a'].str.upper().tolist()\n",
    "        peptides = df['peptide'].str.upper().tolist()\n",
    "\n",
    "        if 'Binding' in df.columns:\n",
    "            Bindings = df['Binding'].tolist()\n",
    "\n",
    "        # Precompute Atchley values for sequences\n",
    "        atchley_matrix_cdr3 = np.zeros((len(cdr3s), length_cdr3, len(features)))\n",
    "        atchley_matrix_peptide = np.zeros((len(peptides), length_pep, len(features)))\n",
    "\n",
    "        for i, cdr3 in enumerate(cdr3s):\n",
    "            for j, char in enumerate(cdr3[:length_cdr3]):\n",
    "                if char in query.index:\n",
    "                    atchley_matrix_cdr3[i, j, :] = query.loc[char].values\n",
    "\n",
    "        for i, peptide in enumerate(peptides):\n",
    "            for j, char in enumerate(peptide[:length_pep]):\n",
    "                if char in query.index:\n",
    "                    atchley_matrix_peptide[i, j, :] = query.loc[char].values\n",
    "\n",
    "        # Compute interaction maps for each feature\n",
    "        for order, feature in enumerate(features):\n",
    "            feature_cdr3 = atchley_matrix_cdr3[:, :, order]\n",
    "            feature_peptide = atchley_matrix_peptide[:, :, order]\n",
    "            intermap = np.abs(feature_cdr3[:, :, None] - feature_peptide[:, None, :])\n",
    "            dict_intermap[feature] = intermap\n",
    "\n",
    "        # Save the combined interaction maps\n",
    "        combinedmap = np.stack([dict_intermap[feature] for feature in features], axis=1)\n",
    "        if chain == 'alpha':\n",
    "            dict_combined['combined_map_alpha'] = combinedmap.tolist()\n",
    "        elif chain == 'beta':\n",
    "            dict_combined['combined_map_beta'] = combinedmap.tolist()\n",
    "\n",
    "        dict_combined['cdr3'] = cdr3s\n",
    "        dict_combined['peptide'] = peptides\n",
    "        if 'Binding' in df.columns:\n",
    "            dict_combined['Binding'] = Bindings\n",
    "\n",
    "        return dict_combined\n",
    "\n",
    "    queryfile = pd.DataFrame(Atchley).T\n",
    "    queryfile.columns = ['f1', 'f2', 'f3', 'f4', 'f5']\n",
    "\n",
    "    data = pd.read_csv(inpath)\n",
    "    data.rename(columns={'CDR3B': 'cdr3b', 'Epitope': 'peptide', 'Affinity': 'Binding'}, inplace=True)\n",
    "    data = data[['cdr3b', 'peptide', 'Binding']]\n",
    "\n",
    "    dict_combined = generate_interaction_map_optimized(\n",
    "        df=data,\n",
    "        query=queryfile,\n",
    "        length_cdr3=length_cdr3,\n",
    "        length_pep=length_pep,\n",
    "        chain=chain )\n",
    "    return dict_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b96a586-eeb5-4879-9c0c-90e4b004e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_retraining(trainfile, testfile, save_model_path, resultfile_path, chain='beta'):\n",
    "    setup_seed(1234)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = TcrPepTransform_single(\n",
    "        input_height=20, \n",
    "        input_width=15, \n",
    "        in_chans=5, \n",
    "        patch_size=4, \n",
    "        num_classes=2, \n",
    "        embed_dim=256, \n",
    "        depth=1, \n",
    "        num_heads=4, \n",
    "        mlp_ratio=4, \n",
    "        qkv_bias=True, \n",
    "        drop_rate=0.1, \n",
    "        attn_drop_rate=0.05, \n",
    "        drop_path_rate=0, \n",
    "        act_layer=torch.nn.GELU\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    model.acc_func = metrics.accuracy_score\n",
    "    model.auc_roc_func = metrics.roc_auc_score\n",
    "    model.auc_pr_func = pr_auc_score\n",
    "    model.f1_score_func = metrics.f1_score\n",
    "    model.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(\"Loading training data...\")\n",
    "    train_dicts = process_file_return_dict(trainfile, chain=chain)\n",
    "    label_train = np.array(train_dicts['Binding'])\n",
    "    label_train_initialized = Labels_Initialization(num_classes=2, labels=label_train)\n",
    "    if chain == 'beta':\n",
    "        data_train = np.array(train_dicts['combined_map_beta'])\n",
    "        raw_cdr3 = train_dicts['cdr3']\n",
    "        raw_epitope = train_dicts['peptide']\n",
    "    elif chain == 'alpha':\n",
    "        data_train = np.array(train_dicts['combined_map_alpha'])\n",
    "        raw_cdr3 = train_dicts['cdr3']\n",
    "        raw_epitope = train_dicts['peptide']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid chain type. Must be 'alpha' or 'beta'.\")\n",
    "    data_train = torch.from_numpy(data_train)\n",
    "    dataset_train = MyDataset(data=data_train, labl=label_train_initialized, raw_cdr3=raw_cdr3, raw_epitope=raw_epitope)\n",
    "    dl_train = DataLoader(dataset_train, batch_size=512, shuffle=True, drop_last=True, num_workers=5)\n",
    "    num_epochs = 100\n",
    "    print(f\"Starting training for {num_epochs} epochs...\")\n",
    "    train_model(\n",
    "        model=model,\n",
    "        dl_train=dl_train,\n",
    "        device=device,\n",
    "        num_epochs=num_epochs )\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    test_dicts = process_file_return_dict(testfile, chain=chain)\n",
    "    label_valid = np.array(test_dicts['Binding'])\n",
    "    label_valid_initialized = Labels_Initialization(num_classes=2, labels=label_valid)\n",
    "\n",
    "    if chain == 'beta':\n",
    "        data_valid = np.array(test_dicts['combined_map_beta'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    elif chain == 'alpha':\n",
    "        data_valid = np.array(test_dicts['combined_map_alpha'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid chain type. Must be 'alpha' or 'beta'.\")\n",
    "\n",
    "    data_valid = torch.from_numpy(data_valid)\n",
    "    dataset_valid = MyDataset(data=data_valid, labl=label_valid_initialized, raw_cdr3=raw_cdr3_test, raw_epitope=raw_epitope_test)\n",
    "    dl_valid = DataLoader(dataset_valid, batch_size=len(data_valid), shuffle=False, num_workers=5)\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    model.eval()\n",
    "    dfhistory = eval_model(\n",
    "        model_initial=model,\n",
    "        dl_valid=dl_valid,\n",
    "        device=device)\n",
    "    dfhistory.to_csv(resultfile_path + 'probability.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3da43f-3206-4f30-bef7-d4ac9a36ed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading training data...\n",
      "Starting training for 100 epochs...\n",
      "Epoch 1: Loss: 0.6935177635401487, AUC-PR: 0.5906857694846539\n"
     ]
    }
   ],
   "source": [
    "trainfile_path =\"../data/train.csv\"\n",
    "testfile_path=\"../data/test.csv\"\n",
    "save_model_path=\"../Retraining_model/Retraining_model.pickle\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Model_retraining(trainfile_path,testfile_path,save_model_path,result_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4329b-eef7-4e90-b00a-2fa1e83d25ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e4ea495",
   "metadata": {},
   "source": [
    "# 3.Retraining_model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eedf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retraining_model_prediction(testfile, save_model_path, resultfile_path, chain='beta'):\n",
    "    setup_seed(1234)\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = TcrPepTransform_single(\n",
    "        input_height=20, \n",
    "        input_width=15, \n",
    "        in_chans=5, \n",
    "        patch_size=4, \n",
    "        num_classes=2, \n",
    "        embed_dim=256, \n",
    "        depth=1, \n",
    "        num_heads=4, \n",
    "        mlp_ratio=4, \n",
    "        qkv_bias=True, \n",
    "        drop_rate=0.1, \n",
    "        attn_drop_rate=0.05, \n",
    "        drop_path_rate=0, \n",
    "        act_layer=torch.nn.GELU)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    model.loss_func = torch.nn.CrossEntropyLoss()\n",
    "    model.acc_func = metrics.accuracy_score\n",
    "    model.auc_roc_func = metrics.roc_auc_score\n",
    "    model.auc_pr_func = pr_auc_score\n",
    "    model.f1_score_func = metrics.f1_score\n",
    "    model.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    " \n",
    "    test_dicts = process_file_return_dict(testfile, chain=chain)\n",
    "    label_valid = np.array(test_dicts['Binding'])\n",
    "    label_valid_initialized = Labels_Initialization(num_classes=2, labels=label_valid)\n",
    "\n",
    "    if chain == 'beta':\n",
    "        data_valid = np.array(test_dicts['combined_map_beta'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    elif chain == 'alpha':\n",
    "        data_valid = np.array(test_dicts['combined_map_alpha'])\n",
    "        raw_cdr3_test = test_dicts['cdr3']\n",
    "        raw_epitope_test = test_dicts['peptide']\n",
    "    else:\n",
    "        raise ValueError(\"Invalid chain type. Must be 'alpha' or 'beta'.\")\n",
    "\n",
    "    data_valid = torch.from_numpy(data_valid)\n",
    "    dataset_valid = MyDataset(data=data_valid, labl=label_valid_initialized, raw_cdr3=raw_cdr3_test, raw_epitope=raw_epitope_test)\n",
    "    dl_valid = DataLoader(dataset_valid, batch_size=len(data_valid), shuffle=False, num_workers=5)\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    model.eval()\n",
    "    dfhistory = eval_model(\n",
    "        model_initial=model,\n",
    "        dl_valid=dl_valid,\n",
    "        device=device)\n",
    "    dfhistory.to_csv(resultfile_path + 'probability.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3aab9f-ab70-421b-a097-e2ff1e5bc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/validation.csv\"\n",
    "modelfile_path=\"../Retraining_model/Retraining_model.pickle\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Retraining_model_prediction(testfile_path,modelfile_path,result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3af9d9-b17f-47f4-8793-6a82a3ed2f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
