{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b013b3",
   "metadata": {},
   "source": [
    "# 1.Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3699ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from data_loader import define_dataloader, load_embedding, load_data_split\n",
    "from utils import str2bool, timeSince, get_performance_batchiter, print_performance, write_blackbox_output_batchiter\n",
    "import data_io_tf\n",
    "\n",
    "\n",
    "class Args:\n",
    "    indepfile=None \n",
    "    blosum=None\n",
    "    batch_size=32\n",
    "    epoch=20\n",
    "    min_epoch=1\n",
    "    early_stop=True \n",
    "    lr=0.001 \n",
    "    cuda=True #True \n",
    "    seed=1039 \n",
    "    mode='train'\n",
    "    save_model=True \n",
    "    model='attention'\n",
    "    drop_rate=0.25        \n",
    "    lin_size=1024 \n",
    "    padding=\"mid\"\n",
    "    heads=5\n",
    "    max_len_tcr=20 \n",
    "    max_len_pep=22\n",
    "    n_fold=5 \n",
    "    idx_test_fold=0\n",
    "    idx_val_fold=-1\n",
    "    #split_type='tcr'\n",
    "\n",
    "def Original_model_prediction(testfile_path,modelfile_path, result_path):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score, matthews_corrcoef, precision_score, auc, roc_curve\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    args = Args()\n",
    "\n",
    "    if torch.cuda.is_available() and not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "\n",
    "    testfile = pd.read_csv(testfile_path)\n",
    "    print(testfile.index)\n",
    "    testfile['idx'] = testfile.index\n",
    "    x_pep = testfile['Epitope'].values\n",
    "    x_tcr = testfile['CDR3B'].values\n",
    "    y = testfile['Affinity'].values\n",
    "\n",
    "    embedding_matrix = load_embedding(args.blosum)\n",
    "    \n",
    "    test_loader = define_dataloader(x_pep, x_tcr, y,\n",
    "                                    maxlen_pep=args.max_len_pep,\n",
    "                                    maxlen_tcr=args.max_len_tcr,\n",
    "                                    padding=args.padding,\n",
    "                                    batch_size=args.batch_size, device=device)\n",
    "    \n",
    "    if args.model == 'attention':\n",
    "        from attention import Net\n",
    "    else:\n",
    "        raise ValueError('unknown model name')\n",
    "    \n",
    "    model = Net(embedding_matrix, args).to(device)\n",
    "    model.load_state_dict(torch.load(modelfile_path, map_location=device))\n",
    "    print('[PREDICT] ----------------')\n",
    "    perf_test = get_performance_batchiter(test_loader['loader'], model, device)\n",
    "    print_performance(perf_test)\n",
    "    wf_open1 = open(result_path + 'probability.csv', 'w', newline='')\n",
    "    wf1 = csv.writer(wf_open1, delimiter=',')\n",
    "    wf1.writerow([ 'Epitope', 'CDR3B', 'y_true', 'y_pred','y_prob'])\n",
    "    write_blackbox_output_batchiter(test_loader, model, wf1, device, ifscore=True)\n",
    "    wf_open1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685126b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/test.csv\"\n",
    "modelfile_path=\"../Original_model/original.ckpt\"\n",
    "result_path=\"../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd5ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae6dc2b6",
   "metadata": {},
   "source": [
    "# 2.Model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47f82731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from data_loader import define_dataloader, load_embedding\n",
    "from utils import get_performance_batchiter, print_performance, write_blackbox_output_batchiter\n",
    "import data_io_tf\n",
    "\n",
    "class Args:\n",
    "    indepfile = None \n",
    "    blosum = None\n",
    "    batch_size = 32\n",
    "    epoch = 50\n",
    "    min_epoch = 1\n",
    "    early_stop = True \n",
    "    lr = 0.001 \n",
    "    cuda = True \n",
    "    seed = 1039 \n",
    "    mode = 'train'\n",
    "    save_model = True \n",
    "    model = 'attention'\n",
    "    drop_rate = 0.25        \n",
    "    lin_size = 1024 \n",
    "    padding = \"mid\"\n",
    "    heads = 5\n",
    "    max_len_tcr = 20 \n",
    "    max_len_pep = 22\n",
    "    n_fold = 5 \n",
    "    idx_test_fold = 0\n",
    "    idx_val_fold = -1\n",
    "\n",
    "def Model_retraining(trainfile_path, testfile_path, save_model_path, result_path):\n",
    "    import pandas as pd\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"gpu enabled\")\n",
    "    else:\n",
    "        print(\"no gpu\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    PRINT_EVERY_EPOCH = 1\n",
    "\n",
    "    def train(model, device, train_loader, optimizer, epoch):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            x_pep, x_tcr, y = batch.X_pep.to(device), batch.X_tcr.to(device), batch.y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(x_pep, x_tcr)\n",
    "            y = y.unsqueeze(-1).expand_as(yhat)\n",
    "            loss = F.binary_cross_entropy(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % PRINT_EVERY_EPOCH == 1:\n",
    "            print('[TRAIN] Epoch {} Loss {:.4f}'.format(epoch, loss.item()))\n",
    "\n",
    "    def evaluate_model(model, device, test_loader):\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_scores = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                x_pep, x_tcr, y = batch.X_pep.to(device), batch.X_tcr.to(device), batch.y.to(device)\n",
    "                yhat = model(x_pep, x_tcr)\n",
    "                y_true.extend(y.cpu().numpy())\n",
    "                y_scores.extend(yhat.cpu().numpy())\n",
    "        \n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "        auprc = auc(recall, precision)\n",
    "        return auprc\n",
    "\n",
    "    args = Args()\n",
    "\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    embedding_matrix = load_embedding(args.blosum)\n",
    "\n",
    "    trainfile = pd.read_csv(trainfile_path)\n",
    "    trainfile = trainfile.reset_index().rename(columns={'index': 'idx'})\n",
    "    testfile = pd.read_csv(testfile_path)\n",
    "    testfile['idx'] = testfile.index + len(trainfile)\n",
    "    alldata = pd.concat([trainfile, testfile], axis=0)\n",
    "    idx_train = trainfile['idx'].tolist()\n",
    "    idx_test = testfile['idx'].tolist()\n",
    "    x_pep = alldata['Epitope'].values\n",
    "    x_tcr = alldata['CDR3B'].values\n",
    "    y = alldata['Affinity'].values\n",
    "\n",
    "    train_loader = define_dataloader(x_pep[idx_train], x_tcr[idx_train], y[idx_train],\n",
    "                                     args.max_len_pep, args.max_len_tcr,\n",
    "                                     padding=args.padding,\n",
    "                                     batch_size=args.batch_size, device=device)\n",
    "    test_loader = define_dataloader(x_pep[idx_test], x_tcr[idx_test], y[idx_test],\n",
    "                                    maxlen_pep=train_loader['pep_length'],\n",
    "                                    maxlen_tcr=train_loader['tcr_length'],\n",
    "                                    padding=args.padding,\n",
    "                                    batch_size=args.batch_size, device=device)\n",
    "\n",
    "    if args.model == 'attention':\n",
    "        from attention import Net\n",
    "    else:\n",
    "        raise ValueError('unknown model name')\n",
    "\n",
    "    model = Net(embedding_matrix, args).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    if args.mode == 'train':\n",
    "        t0 = time.time()\n",
    "        lossArraySize = 10\n",
    "        lossArray = deque([sys.maxsize], maxlen=lossArraySize)\n",
    "        for epoch in range(1, args.epoch + 1):\n",
    "            train(model, device, train_loader['loader'], optimizer, epoch)\n",
    "            perf_test = get_performance_batchiter(test_loader['loader'], model, device)\n",
    "            lossArray.append(perf_test['loss'])\n",
    "            average_loss_change = sum(np.abs(np.diff(lossArray))) / lossArraySize\n",
    "            auprc = evaluate_model(model, device, test_loader['loader'])\n",
    "            print(f'[EPOCH {epoch}] AUPRC: {auprc:.4f}')\n",
    "\n",
    "            if epoch > args.min_epoch and average_loss_change < 10 and args.early_stop:\n",
    "                break\n",
    "        \n",
    "        print('[TEST ] {} ----------------'.format(epoch))\n",
    "        perf_test = get_performance_batchiter(test_loader['loader'], model, device)\n",
    "        print_performance(perf_test)\n",
    "\n",
    "        if args.save_model:\n",
    "            wf_open1 = open(result_path + 'probability.csv', 'w', newline='')\n",
    "            wf1 = csv.writer(wf_open1, delimiter=',')\n",
    "            wf1.writerow(['Epitope', 'CDR3B', 'y_true', 'y_pred', 'y_prob'])\n",
    "            write_blackbox_output_batchiter(test_loader, model, wf1, device, ifscore=True)\n",
    "            wf_open1.close()\n",
    "                        \n",
    "            torch.save(model.state_dict(), save_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile_path =\"../data/train.csv\"\n",
    "testfile_path=\"../data/test.csv\"\n",
    "save_modle_path=\"../Retraining_model/Retraining_model.ckpt\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Model_retraining(trainfile_path,testfile_path,save_modle_path,result_path) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2d75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b921e0b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92b66dc5",
   "metadata": {},
   "source": [
    "# 3.Retraining_model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d49d1a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from data_loader import define_dataloader, load_embedding, load_data_split\n",
    "from utils import str2bool, timeSince, get_performance_batchiter, print_performance, write_blackbox_output_batchiter\n",
    "import data_io_tf\n",
    "\n",
    "\n",
    "class Args:\n",
    "    indepfile=None \n",
    "    blosum=None\n",
    "    batch_size=32\n",
    "    epoch=20\n",
    "    min_epoch=1\n",
    "    early_stop=True \n",
    "    lr=0.001 \n",
    "    cuda=True #True \n",
    "    seed=1039 \n",
    "    mode='train'\n",
    "    save_model=True \n",
    "    model='attention'\n",
    "    drop_rate=0.25        \n",
    "    lin_size=1024 \n",
    "    padding=\"mid\"\n",
    "    heads=5\n",
    "    max_len_tcr=20 \n",
    "    max_len_pep=22\n",
    "    n_fold=5 \n",
    "    idx_test_fold=0\n",
    "    idx_val_fold=-1\n",
    "    #split_type='tcr'\n",
    "\n",
    "def Retraining_model_prediction(testfile_path,modelfile_path, result_path):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, f1_score, matthews_corrcoef, precision_score, auc, roc_curve\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    args = Args()\n",
    "\n",
    "    if torch.cuda.is_available() and not args.cuda:\n",
    "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "    device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "\n",
    "    testfile = pd.read_csv(testfile_path)\n",
    "    print(testfile.index)\n",
    "    testfile['idx'] = testfile.index\n",
    "    x_pep = testfile['Epitope'].values\n",
    "    x_tcr = testfile['CDR3B'].values\n",
    "    y = testfile['Affinity'].values\n",
    "\n",
    "    embedding_matrix = load_embedding(args.blosum)\n",
    "    \n",
    "    test_loader = define_dataloader(x_pep, x_tcr, y,\n",
    "                                    maxlen_pep=args.max_len_pep,\n",
    "                                    maxlen_tcr=args.max_len_tcr,\n",
    "                                    padding=args.padding,\n",
    "                                    batch_size=args.batch_size, device=device)\n",
    "    \n",
    "    if args.model == 'attention':\n",
    "        from attention import Net\n",
    "    else:\n",
    "        raise ValueError('unknown model name')\n",
    "    \n",
    "    model = Net(embedding_matrix, args).to(device)\n",
    "    model.load_state_dict(torch.load(modelfile_path, map_location=device))\n",
    "    print('[PREDICT] ----------------')\n",
    "    perf_test = get_performance_batchiter(test_loader['loader'], model, device)\n",
    "    print_performance(perf_test)\n",
    "    wf_open1 = open(result_path + 'probability.csv', 'w', newline='')\n",
    "    wf1 = csv.writer(wf_open1, delimiter=',')\n",
    "    wf1.writerow([ 'Epitope', 'CDR3B', 'y_true', 'y_pred','y_prob'])\n",
    "    write_blackbox_output_batchiter(test_loader, model, wf1, device, ifscore=True)\n",
    "    wf_open1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5acd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/Validation.csv\"\n",
    "modelfile_path=\"../Retraining_model/Retraining_model.ckpt\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Retraining_model_prediction(testfile_path,modelfile_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa0cef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATM",
   "language": "python",
   "name": "atm-tcr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
