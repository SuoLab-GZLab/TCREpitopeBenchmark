{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5fcffa3",
   "metadata": {},
   "source": [
    "# 1.Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c14c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tpbte import Model\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, emb_type):\n",
    "\n",
    "        self.data = pd.read_csv(path,low_memory=False)\n",
    "        self.CDR3B = self.data['CDR3B']\n",
    "        self.Epitope = self.data['Epitope']\n",
    "        self.Affinity = self.data['Affinity']\n",
    "        self.emb_type = emb_type\n",
    "        if self.emb_type == 'onehot':\n",
    "            CDR3B, Epi, self.Affinity = onehot(self.CDR3B, self.Epitope, self.Affinity)\n",
    "        elif self.emb_type == 'BLOSUM62':\n",
    "            CDR3B, Epi, self.Affinity = BLOSUM_62(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        else:\n",
    "            CDR3B, Epi, self.Affinity = Atchley(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        self.pair = torch.cat((CDR3B, Epi), -1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.pair[index], self.Affinity[index]\n",
    "    def __len__(self):\n",
    "        return torch.LongTensor(self.Affinity).size()[0]\n",
    "\n",
    "def Atchley(TCR, Epitope, Label, Length):\n",
    "    aa_vec = pk.load(open('atchley.pk', 'rb'))\n",
    "    Label = torch.LongTensor(Label).view(-1, 1)\n",
    "    n = Label.size()[0]\n",
    "    ext = list('********************') \n",
    "    tcr_embedding = torch.zeros(n, Length, 6)\n",
    "    epi_embedding = torch.zeros(n, Length, 6)\n",
    "    for ti, tcr in enumerate(TCR):\n",
    "        tcr = tcr + ' ' * (Length - len(tcr))\n",
    "        for i in range(Length):\n",
    "            tcr_embedding[ti, i, :] = torch.from_numpy(aa_vec[tcr[i]])\n",
    "\n",
    "    for ei, epi in enumerate(Epitope):\n",
    "        epi = epi + ' ' * (Length - len(epi))\n",
    "        for i in range(Length):\n",
    "            epi_embedding[ei, i, :] = torch.from_numpy(aa_vec[epi[i]])\n",
    "    return tcr_embedding[:, :, 0:5], epi_embedding[:, :, 0:5], Label \n",
    "\n",
    "def Convert_letters(seq):\n",
    "    result = []\n",
    "    atchley = pk.load(open('atchley.pk', 'rb'))\n",
    "    for key in atchley.keys():\n",
    "        atchley[key] = atchley[key][..., :-1]\n",
    "    for row in seq:\n",
    "        res_row = []\n",
    "        for element in row:\n",
    "            closest_key = None\n",
    "            min_distance = float('inf')\n",
    "            for key, value in atchley.items():\n",
    "                distance = np.linalg.norm(element - value)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_key = key\n",
    "            res_row.append([closest_key])\n",
    "        result.append(res_row)\n",
    "    result = np.array(result, dtype=object)\n",
    "    shape = result.shape\n",
    "    result = result.reshape((shape[0], shape[1]*shape[2]))\n",
    "    letter = []\n",
    "    for row in result:\n",
    "        row_without_symbols = [element for element in row if element.isalpha()]\n",
    "        letter.append(''.join(row_without_symbols))\n",
    "    return letter\n",
    "\n",
    "def data_renew(pairs, emb_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if emb_type == 'onehot':\n",
    "        tcr = pairs[:, :, 0:21].type(torch.LongTensor).to(device)\n",
    "        epi = pairs[:, :, 21:-1].type(torch.LongTensor).to(device)\n",
    "    elif emb_type == 'BLOSUM62':\n",
    "        tcr = pairs[:, :, 0:20].to(device)\n",
    "        epi = pairs[:, :, 20:].to(device)\n",
    "    else:\n",
    "        tcr = pairs[:, :, 0:5].to(device)\n",
    "        epi = pairs[:, :, 5:].to(device)\n",
    "    return tcr, epi\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def Original_model_prediction(testfile_path,modelfile_path,result_path):\n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    test_path=testfile_path\n",
    "    test = MyDataset(test_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model, dropout=0.1, device=device)\n",
    "    model.load_state_dict(torch.load(modelfile_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    df_data = []\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    predicted_classes=[]\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataset:\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            tcr = tcr.to(device)\n",
    "            epi = epi.to(device)\n",
    "            output = model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/test.csv\"\n",
    "modelfile_path=\"../Original_model/TPBTE_mc.pth\"\n",
    "result_path=\"../result_path/Original_model_prediction\"\n",
    "Original_model_prediction(testfile_path,modelfile_path,result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ad689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69c55710",
   "metadata": {},
   "source": [
    "# 2.Model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a50c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef,roc_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tpbte import Model\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "def data_renew(pairs, emb_type):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if emb_type == 'onehot':\n",
    "        tcr = pairs[:, :, 0:21].type(torch.LongTensor).to(device)\n",
    "        epi = pairs[:, :, 21:-1].type(torch.LongTensor).to(device)\n",
    "    elif emb_type == 'BLOSUM62':\n",
    "        tcr = pairs[:, :, 0:20].to(device)\n",
    "        epi = pairs[:, :, 20:].to(device)\n",
    "    else:\n",
    "        tcr = pairs[:, :, 0:5].to(device)\n",
    "        epi = pairs[:, :, 5:].to(device)\n",
    "    return tcr, epi\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, path, emb_type):\n",
    "\n",
    "        self.data = pd.read_csv(path,low_memory=False)\n",
    "        self.CDR3B = self.data['CDR3B']\n",
    "        self.Epitope = self.data['Epitope']\n",
    "        self.Affinity = self.data['Affinity']\n",
    "        self.emb_type = emb_type\n",
    "        if self.emb_type == 'onehot':\n",
    "            CDR3B, Epi, self.Affinity = onehot(self.CDR3B, self.Epitope, self.Affinity)\n",
    "        elif self.emb_type == 'BLOSUM62':\n",
    "            CDR3B, Epi, self.Affinity = BLOSUM_62(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        else:\n",
    "            CDR3B, Epi, self.Affinity = Atchley(self.CDR3B, self.Epitope, self.Affinity, 20)\n",
    "        self.pair = torch.cat((CDR3B, Epi), -1)\n",
    "    def __getitem__(self, index):\n",
    "        return self.pair[index], self.Affinity[index]\n",
    "    def __len__(self):\n",
    "        return torch.LongTensor(self.Affinity).size()[0]\n",
    "def Atchley(TCR, Epitope, Label, Length):\n",
    "    aa_vec = pk.load(open('atchley.pk', 'rb'))\n",
    "    Label = torch.LongTensor(Label).view(-1, 1)\n",
    "    n = Label.size()[0]\n",
    "    ext = list('********************') \n",
    "    tcr_embedding = torch.zeros(n, Length, 6)\n",
    "    epi_embedding = torch.zeros(n, Length, 6)\n",
    "    for ti, tcr in enumerate(TCR):\n",
    "        tcr = tcr + ' ' * (Length - len(tcr))\n",
    "        for i in range(Length):\n",
    "            tcr_embedding[ti, i, :] = torch.from_numpy(aa_vec[tcr[i]])\n",
    "\n",
    "    for ei, epi in enumerate(Epitope):\n",
    "        epi = epi + ' ' * (Length - len(epi))\n",
    "        for i in range(Length):\n",
    "            epi_embedding[ei, i, :] = torch.from_numpy(aa_vec[epi[i]])\n",
    "    return tcr_embedding[:, :, 0:5], epi_embedding[:, :, 0:5], Label \n",
    "\n",
    "def Convert_letters(seq):\n",
    "    import numpy as np\n",
    "    result = []\n",
    "    atchley = pk.load(open('atchley.pk', 'rb'))\n",
    "    for key in atchley.keys():\n",
    "        atchley[key] = atchley[key][..., :-1]\n",
    "    for row in seq:\n",
    "        res_row = []\n",
    "        for element in row:\n",
    "            closest_key = None\n",
    "            min_distance = float('inf')\n",
    "            for key, value in atchley.items():\n",
    "                distance = np.linalg.norm(element - value)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_key = key\n",
    "            res_row.append([closest_key])\n",
    "        result.append(res_row)\n",
    "    result = np.array(result, dtype=object)\n",
    "    shape = result.shape\n",
    "    result = result.reshape((shape[0], shape[1]*shape[2]))\n",
    "    letter = []\n",
    "    for row in result:\n",
    "        row_without_symbols = [element for element in row if element.isalpha()]\n",
    "        letter.append(''.join(row_without_symbols))\n",
    "    return letter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45ef345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_retraining(trainfile_path,testfile_path,save_model_path,result_path): \n",
    "    import pandas as pd\n",
    "    import numpy as np \n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model,dropout=0.1, device=device)\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.00005, betas=(0.9, 0.98), eps=1e-9)\n",
    "    n_epoch = 2\n",
    "    train = MyDataset(trainfile_path, emb_type=e_type)\n",
    "    test = MyDataset(testfile_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    train_dataset = DataLoader(dataset=train, batch_size=b_size, shuffle=True, drop_last=True) \n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model.train()\n",
    "    best_loss = 1\n",
    "    L = torch.zeros(n_epoch, 500)\n",
    "    predictions = []  # Initialize predictions list\n",
    "    true_labels = []  # Initialize true_labels list\n",
    "    predicted_classes = []  # Initialize predicted_classes list\n",
    "    for epoch in range(n_epoch):\n",
    "        print('epoch:', epoch + 1)\n",
    "        for i, data in enumerate(train_dataset, 0):\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            label = label.unsqueeze(-1).to(device)\n",
    "            n = tcr.size()[0]\n",
    "            output = torch.unsqueeze(model(tcr, epi), 1)\n",
    "            pred = output.argmax(dim=2)\n",
    "            output = output.view(-1, 2)\n",
    "            pred = pred.view(-1)\n",
    "            label = label.long().view(-1)\n",
    "            loss = criterion(output, label) \n",
    "            correct = torch.eq(pred, label.long()).sum().float().item()\n",
    "            acc = correct / n\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                param = model.state_dict()\n",
    "            if loss == best_loss:\n",
    "                param = model.state_dict()\n",
    "            opt.zero_grad()\n",
    "            loss.backward() \n",
    "            opt.step()\n",
    "    torch.save(model.state_dict(),save_model_path)  \n",
    "    print('End training. Begin testing')\n",
    "    good_model = model\n",
    "    good_model.load_state_dict(param)\n",
    "    good_model.eval()\n",
    "    good_model.to(device)\n",
    "    df_data = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_dataset, 0):\n",
    "            correct = 0  \n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            output = good_model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "            torch.cuda.empty_cache()\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile_path =\"../data/train.csv\"\n",
    "testfile_path=\"../data/test.csv\"\n",
    "save_modle_path=\"../Retraining_model/Retraining_model.pth\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Model_retraining(trainfile_path,testfile_path,save_modle_path,result_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366d79bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6a7b8f",
   "metadata": {},
   "source": [
    "# 3.Retraining_model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e2b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retraining_model_prediction(testfile_path,modelfile_path,result_path):\n",
    "    vocab = 21 \n",
    "    d_model = 512\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    e_type = 'Atchley'\n",
    "    test_path=testfile_path\n",
    "    test = MyDataset(test_path, emb_type=e_type)\n",
    "    b_size = 32\n",
    "    test_dataset = DataLoader(dataset=test, batch_size=b_size, shuffle=True, drop_last=False)\n",
    "    model = Model(src_vocab=vocab, tgt_vocab=vocab, emb_type=e_type, N=6, h=8, d_model=d_model, dropout=0.1, device=device)\n",
    "    model.load_state_dict(torch.load(modelfile_path))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    df_data = []\n",
    "    predictions=[]\n",
    "    true_labels=[]\n",
    "    predicted_classes=[]\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataset:\n",
    "            pairs, label = data\n",
    "            tcr, epi = data_renew(pairs=pairs, emb_type=e_type)\n",
    "            tcr = tcr.to(device)\n",
    "            epi = epi.to(device)\n",
    "            output = model(tcr, epi)\n",
    "            pred = output.argmax(dim=1)\n",
    "            predictions.extend(output[:, 1].tolist())  \n",
    "            true_labels.extend(label.tolist())\n",
    "            predicted_classes.extend(pred.tolist())\n",
    "            tcr=Convert_letters(tcr.cpu().numpy())\n",
    "            epi=Convert_letters(epi.cpu().numpy())\n",
    "            prediction_scores = output[:, 1].cpu().numpy()\n",
    "            true_labels_batch = label.cpu().numpy()\n",
    "            predicted_classes_batch = pred.cpu().numpy()\n",
    "            for i in range(len(pairs)):\n",
    "                 df_data.append({'Epitope': epi[i],'CDR3B': tcr[i],'y_true': true_labels_batch[i],\n",
    "                                 'y_prob': prediction_scores[i], \n",
    "                                 'y_pred': predicted_classes_batch[i]})\n",
    "    df_data=pd.DataFrame(df_data)           \n",
    "    df_data['y_true'] = df_data['y_true'].str[0]\n",
    "    df_data.to_csv(result_path+'probability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../data/Validation.csv\"\n",
    "modelfile_path=\"../Retraining_model/Retraining_model.pth\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Retraining_model_prediction(testfile_path,modelfile_path,result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac4b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
