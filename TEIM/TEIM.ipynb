{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f94d319",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Before running this model, convert the data format using the following code'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4069771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def fix_name(path,save_path):\n",
    "    data=pd.read_csv(path)\n",
    "    data=data[['CDR3B','Epitope','Affinity']]\n",
    "    data.rename(columns={'CDR3B': 'cdr3', 'Epitope': 'epi', 'Affinity': 'y_true'}, inplace=True)\n",
    "    data.to_csv(save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ee1c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path='../data/test.csv'\n",
    "save_path='../data/test_TEIM.csv'\n",
    "fix_name(path,save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d871d7",
   "metadata": {},
   "source": [
    "# 1.Original model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c967ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run script path\n",
    "cd  \"TEIM/Original_model_prediciton\"\n",
    "python  Original_prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b43243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c1768b5",
   "metadata": {},
   "source": [
    "# 2.Model retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc439410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "GPU_NUMBER = [0]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join([str(s) for s in GPU_NUMBER])\n",
    "os.environ[\"NCCL_DEBUG\"] = \"INFO\"\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(0)\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from scripts.model_raw import TEIM\n",
    "from utils.misc import load_config, calc_auc_aupr\n",
    "from utils.dataset import load_data, SeqLevelDataset\n",
    "import os\n",
    "\n",
    "\n",
    "class SeqLevelSystem(pl.LightningModule):\n",
    "    def __init__(self, config, train_set, val_set):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.lr = config.training.lr\n",
    "        self.teim_seq = TEIM(config.model)\n",
    "        self.train_set = train_set\n",
    "        self.val_set = val_set\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.config.training.batch_size, shuffle=True)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.config.training.batch_size, shuffle=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.teim_seq(x)['seqlevel_out']\n",
    "    \n",
    "    def minimum_step(self, batch, device=None):\n",
    "        # batch = batch.to(self.device)\n",
    "        if device is None:\n",
    "            cdr3, epi, labels = batch['cdr3'], batch['epi'], batch['labels']\n",
    "        else:\n",
    "            cdr3, epi, labels = batch['cdr3'].to(device), batch['epi'].to(device), batch['labels'].to(device)\n",
    "        pred = self([cdr3, epi])\n",
    "        loss = self.get_loss(pred, labels)\n",
    "        return loss, labels, pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.train()\n",
    "        loss, labels, pred = self.minimum_step(batch)\n",
    "        self.log('train/loss', loss)\n",
    "        \n",
    "        return {\n",
    "            'loss':loss,\n",
    "            'labels': labels,\n",
    "            'pred': pred\n",
    "        }\n",
    "\n",
    "    def training_epoch_end(self, training_step_outputs):\n",
    "        \n",
    "        ## training metric\n",
    "        loss, auc, aupr, auc_mean, aupr_mean = self.evaluate_model(self.train_dataloader())\n",
    "\n",
    "        print('Train set: AUC={:.4}, AUPR={:.4}, AUC_AVG={:.4}, AUPR_AVG={:.4}'.format(auc, aupr, auc_mean, aupr_mean))\n",
    "        self.log('lr', self.optimizers().state_dict()['param_groups'][0]['lr'])\n",
    "        self.log_dict({\n",
    "            'train/auc':auc,\n",
    "            'train/aupr':aupr,\n",
    "            'train/auc_avg':auc_mean,\n",
    "            'train/aupr_avg':aupr_mean,\n",
    "        }, prog_bar=False)\n",
    "\n",
    "        \n",
    "\n",
    "        ## validating metric\n",
    "        loss, auc, aupr, auc_mean, aupr_mean = self.evaluate_model(self.val_dataloader())\n",
    "        print('Valid', ' set: AUC={:.4}, AUPR={:.4}, AUC_AVG={:.4}, AUPR_AVG={:.4}'.format(auc, aupr, auc_mean, aupr_mean))\n",
    "        self.log_dict({\n",
    "            'valid/loss':loss,\n",
    "            'valid/auc':auc,\n",
    "            'valid/aupr':aupr,\n",
    "            'valid/auc_avg':auc_mean,\n",
    "            'valid/aupr_avg':aupr_mean,\n",
    "        }, prog_bar=False)\n",
    "\n",
    "\n",
    "    def evaluate_model(self, data_loader=None, ):\n",
    "        self.eval()\n",
    "        loss = 0\n",
    "        y_true, y_pred = [], []\n",
    "        epi_ids = []\n",
    "\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            loss_this, y, y_hat = self.minimum_step(batch, self.device)\n",
    "            loss += loss_this.item()\n",
    "            y_true.extend(y.cpu().numpy().tolist())\n",
    "            y_pred.extend(y_hat.detach().cpu().numpy().tolist())\n",
    "            if 'epi_id' in batch:\n",
    "                epi_ids.extend(batch['epi_id'].cpu().numpy().tolist())\n",
    "        loss /= (i+1)\n",
    "        auc, aupr = self.get_scores(y_true, y_pred)\n",
    "        print(auc)\n",
    "        print(aupr)\n",
    "        ## per epi auc\n",
    "        if len(epi_ids) > 0:\n",
    "            ids_uni = np.unique(epi_ids, axis=0)\n",
    "            print(ids_uni.shape)\n",
    "\n",
    "            auc_sum = 0\n",
    "            aupr_sum = 0\n",
    "            cnt = 0\n",
    "            for i, id_ in enumerate(ids_uni):\n",
    "                index = np.array(epi_ids == id_)\n",
    "                y_true_epi = np.array(y_true)[index]\n",
    "                y_pred_epi = np.array(y_pred)[index]\n",
    "                auc_epi, aupr_epi = self.get_scores(y_true_epi, y_pred_epi)\n",
    "                if auc_epi is None:\n",
    "                    continue\n",
    "                auc_sum += auc_epi\n",
    "                aupr_sum += aupr_epi\n",
    "                cnt += 1\n",
    "            auc_mean = auc_sum / cnt\n",
    "            aupr_mean = aupr_sum / cnt\n",
    "        else:\n",
    "            auc_mean, aupr_mean = auc, aupr\n",
    "\n",
    "        return loss, auc, aupr, auc_mean, aupr_mean\n",
    "\n",
    "\n",
    "    def predict(self, data_loader=None):\n",
    "        self.eval()\n",
    "        cdr3_seqs, epi_seqs, y_true, y_pred = [], [], [], []\n",
    "        epi_ids = []\n",
    "\n",
    "        for i, batch in tqdm(enumerate(data_loader), desc='Predicting'):\n",
    "            loss, y, y_hat = self.minimum_step(batch, self.device)\n",
    "            cdr3_seqs.extend(batch['cdr3_seqs'])\n",
    "            epi_seqs.extend(batch['epi_seqs'])\n",
    "            y_true.extend(y.cpu().numpy().tolist())\n",
    "            y_pred.extend(y_hat.detach().cpu().numpy().tolist())\n",
    "            if 'epi_id' in batch.keys():\n",
    "                epi_ids.extend(batch['epi_id'].cpu().numpy().tolist())\n",
    "\n",
    "        if len(epi_ids) > 0:\n",
    "            return cdr3_seqs, epi_seqs, y_true, np.reshape(y_pred, -1), epi_ids\n",
    "        else:\n",
    "            return cdr3_seqs, epi_seqs, y_true, np.reshape(y_pred, -1)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def get_loss(self, pred, labels):\n",
    "        loss = F.binary_cross_entropy(pred.view(-1), labels.float(), weight=None, reduction='mean')\n",
    "        return loss\n",
    "\n",
    "    def get_scores(self, y_true, y_pred):\n",
    "        if len(np.unique(y_true)) == 1:\n",
    "            return None, None\n",
    "        else:\n",
    "            return calc_auc_aupr(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4234a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'configs/seqlevel_all.yml'\n",
    "config = load_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e277510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_retraining(trainfile_path, testfile_path, train_name, test_name,save_model_path, result_path):\n",
    "    class Config:\n",
    "        def __init__(self, path, file_list):\n",
    "            self.path = path\n",
    "            self.file_list = file_list\n",
    "\n",
    "    config_path = 'configs/seqlevel_all.yml'\n",
    "    config = load_config(config_path)  \n",
    "\n",
    "    train_set = SeqLevelDataset(Config(path=trainfile_path, file_list=[train_name])) \n",
    "    val_set = SeqLevelDataset(Config(path=testfile_path, file_list=[test_name])) \n",
    "\n",
    "    model = SeqLevelSystem(config, train_set, val_set)\n",
    "    checkpoint = ModelCheckpoint(monitor='valid/auc_avg', save_last=True, mode='max', save_top_k=1)\n",
    "    earlystop = EarlyStopping(monitor='valid/auc_avg', patience=15, mode='max')\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.training.epochs,\n",
    "        gpus=1,\n",
    "        callbacks=[checkpoint, earlystop],\n",
    "        default_root_dir=os.path.join(os.getcwd(), 'logs', config.name)\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "    #model_save_path = os.path.join(save_model_path, 'model.pth')\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    shutil.copy2(config_path, os.path.join(trainer.log_dir, os.path.basename(config_path)))\n",
    "\n",
    "    print('Predicting and saving results...')\n",
    "    results = model.predict(model.val_dataloader())\n",
    "    columns = ['CDR3B', 'Epitope', 'y_true', 'y_prob']\n",
    "    if len(results) == 4:\n",
    "        pd.DataFrame(zip(*results), columns=['CDR3B', 'Epitope', 'y_true', 'y_prob']).to_csv(result_path+'probability.csv', index=False)\n",
    "    else:\n",
    "        aa= pd.DataFrame(zip(*results), columns=['CDR3B', 'Epitope', 'y_true', 'y_prob', 'epi_id'])\n",
    "        aa=aa[['CDR3B', 'Epitope', 'y_true', 'y_prob']]\n",
    "        aa['y_pred'] = aa['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        aa.to_csv(result_path+'probability.csv', index=False)\n",
    "    print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce3acfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../data/train.csv'\n",
    "save_path='../data/train_TEIM.csv'\n",
    "fix_name(path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b689451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name='train_TEIM'\n",
    "test_name='test_TEIM'\n",
    "trainfile_path =\"../data/\"\n",
    "testfile_path=\"../data/\"\n",
    "save_model_path=\"../Retraining_model/Retraining_model.pth\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Model_retraining(trainfile_path,testfile_path,train_name,test_name,save_model_path,result_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7cc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f1aba98",
   "metadata": {},
   "source": [
    "# 3.Retraining_model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dff69fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retraining_model_prediction(trainfile_path,testfile_path,train_name,test_name,model_path,result_path):\n",
    "    test_name=test_name\n",
    "    train_name=train_name\n",
    "    class Config:\n",
    "        def __init__(self, path, file_list):\n",
    "            self.path = path\n",
    "            self.file_list = file_list\n",
    "    train_set = SeqLevelDataset(Config(path=trainfile_path, file_list=[train_name]))\n",
    "    val_set = SeqLevelDataset(Config(path=testfile_path, file_list=[test_name]))\n",
    "    ckpt_path = model_path\n",
    "    model = SeqLevelSystem(config, train_set, val_set)\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    print('Predicting val...')\n",
    "    results = model.predict(model.val_dataloader())\n",
    "    print('Saving results...')\n",
    "    if len(results) == 4:\n",
    "        pd.DataFrame(zip(*results), columns=['CDR3B', 'Epitope', 'y_true', 'y_prob']).to_csv(result_path+'probability.csv', index=False)\n",
    "    else:\n",
    "        aa=pd.DataFrame(zip(*results), columns=['CDR3B', 'Epitope', 'y_true', 'y_prob', 'epi_id'])\n",
    "        aa=aa[['CDR3B', 'Epitope', 'y_true', 'y_prob']]\n",
    "        aa['y_pred'] = aa['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        aa.to_csv(result_path+'probability.csv', index=False)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2818f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../data/train.csv'\n",
    "save_path='../data/train_TEIM.csv'\n",
    "fix_name(path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_name='train_TEIM'\n",
    "test_name='test_TEIM'\n",
    "trainfile_path =\"../data/\"\n",
    "testfile_path=\"../data/\"\n",
    "modela_path=\"../Retraining_model/Retraining_model.pth\"\n",
    "result_path=\"../result_path/Retraining_model_prediction\"\n",
    "Retraining_model_prediction(trainfile_path,testfile_path,train_name,test_name,modela_path,result_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d14bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teim",
   "language": "python",
   "name": "teim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
