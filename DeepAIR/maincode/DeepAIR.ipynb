{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7e842d-16ec-4359-b4f8-53a80ffa6e5e",
   "metadata": {},
   "source": [
    "#When running this file, first run the **Data preprocessing for input** Jupyter notebook located in the `preprocessing_structure_feature` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae45f82e-6204-4fd9-bde9-ec4ed6c6c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import umap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "\n",
    "path='./maincode/'\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "\n",
    "from config import DeepAIR_BRP_saved_model_dict\n",
    "from deepair.modelling.classification import SeqClassificationModelWithProcessor\n",
    "from deepair.utility.utility import df_to_input_feature_extraction\n",
    "from deepair.utility.utility import generate_AF2_feature_on_the_fly\n",
    "\n",
    "from DeepAIR_Transformer_Feature_Extraction import generate_transformer_feature_on_the_fly\n",
    "\n",
    "#%%\n",
    "def model_seed_set(model_seed=13):\n",
    "    os.environ['PYTHONHASHSEED']=str(model_seed)\n",
    "    np.random.seed(model_seed)\n",
    "    tf.random.set_seed(model_seed)\n",
    "    \n",
    "def map_probability_to_prediction(input, threshold):\n",
    "    output = list()\n",
    "    N, M = np.shape(input)\n",
    "    for i in range(N):\n",
    "        output.append(int(input[i,0]>=threshold))\n",
    "    return output    \n",
    "\n",
    "def calculate_performance(y_test, preds, output_folder, curr_epitope, output_per_note='AUC'):\n",
    "    output_performance = {output_per_note: metrics.roc_auc_score(y_test, preds)}\n",
    "    output_performance_value = output_performance[output_per_note]\n",
    "    print(\" \\n\\n model evaluation : \", output_performance)\n",
    "    print(\" \\n\\n \")\n",
    "    output_file = os.path.join(output_folder, curr_epitope+'_Test{}-{}_performance.txt'.format(output_per_note, output_performance_value))\n",
    "    with open(output_file, 'w+') as f:\n",
    "        print(\" \\n\\n model evaluation : \", output_performance, file=f)\n",
    "\n",
    "def predict(input_data_file, \n",
    "            transformer_model_folder,\n",
    "            seq_transformer_info,\n",
    "            AF2_Feature_Info, \n",
    "            selected_epitope = None, \n",
    "            output_folder = None,\n",
    "            label_column_name = None,\n",
    "            output_per_note='AUC',\n",
    "            task_name='unseen'\n",
    "            ):\n",
    "    \n",
    "    # print('-'*30)\n",
    "    # print(f'current epitope is {epitope}')\n",
    "    \n",
    "    if output_folder:\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    df = pd.read_csv(input_data_file)  \n",
    "\n",
    "    if 'Heavy_cdr3' in list(df.columns):\n",
    "        cell_type = 'BCELL'\n",
    "        input_df=df.rename(columns={'Heavy_cdr3':'TRB_cdr3',\n",
    "                            'Heavy_v_gene':'TRB_v_gene',\n",
    "                            'Heavy_j_gene':'TRB_j_gene',\n",
    "                            'Light_cdr3':'TRA_cdr3',\n",
    "                            'Light_v_gene':'TRA_v_gene',\n",
    "                            'Light_j_gene':'TRA_j_gene',\n",
    "                            })\n",
    "    else:\n",
    "        cell_type = 'TCELL'\n",
    "        input_df=df\n",
    "        \n",
    "    # add transformer features\n",
    "    seq_trans_beta_feature, seq_trans_alpha_feature = generate_transformer_feature_on_the_fly(input_df,\n",
    "                                                         transformer_model_folder,\n",
    "                                                         seq_transformer_info = seq_transformer_info\n",
    "        )    \n",
    "    # add AF2 structure features\n",
    "    AF2_feature_beta_feature, AF2_feature_alpha_feature = generate_AF2_feature_on_the_fly(input_df, \n",
    "                                                                                        AF2_Feature_Info,\n",
    "                                                                                        CDR3b = 'TRB_cdr3', \n",
    "                                                                                        b_vgene = 'TRB_v_gene',\n",
    "                                                                                        b_jgene = 'TRB_j_gene',\n",
    "                                                                                        CDR3a = 'TRA_cdr3', \n",
    "                                                                                        a_vgene = 'TRA_v_gene',\n",
    "                                                                                        a_jgene = 'TRA_j_gene',\n",
    "                                                                                        task_name = task_name,\n",
    "                                                                                        ID = 'ID', \n",
    "                                                                                    )\n",
    "\n",
    "    test_input = df_to_input_feature_extraction(input_df)\n",
    "    test_input['TRB_cdr3_splited'] = seq_trans_beta_feature\n",
    "    test_input['TRA_cdr3_splited'] = seq_trans_alpha_feature\n",
    "    test_input['TRB_cdr3_Stru'] = AF2_feature_beta_feature\n",
    "    test_input['TRA_cdr3_Stru'] = AF2_feature_alpha_feature\n",
    "        \n",
    "    output_df = pd.DataFrame()\n",
    "    if cell_type == 'TCELL':\n",
    "        output_df['ID'] = test_input['ID']\n",
    "        output_df['TRB_cdr3'] = test_input['TRB_cdr3']\n",
    "        output_df['TRA_cdr3'] = test_input['TRA_cdr3']\n",
    "        output_df['TRB_v_gene'] = test_input['TRB_v_gene']\n",
    "        output_df['TRB_j_gene'] = test_input['TRB_j_gene']\n",
    "        output_df['TRA_v_gene'] = test_input['TRA_v_gene']\n",
    "        output_df['TRA_j_gene'] = test_input['TRA_j_gene']\n",
    "    else:\n",
    "        output_df['ID'] = test_input['ID']\n",
    "        output_df['Heavy_cdr3'] = test_input['TRB_cdr3']\n",
    "        output_df['Light_cdr3'] = test_input['TRA_cdr3']\n",
    "        output_df['Heavy_v_gene'] = test_input['TRB_v_gene']\n",
    "        output_df['Heavy_j_gene'] = test_input['TRB_j_gene']\n",
    "        output_df['Light_v_gene'] = test_input['TRA_v_gene']\n",
    "        output_df['Light_j_gene'] = test_input['TRA_j_gene']\n",
    "    \n",
    "    for curr_epitope in selected_epitope: \n",
    "        \n",
    "        \n",
    "        model_save_path = DeepAIR_BRP_saved_model_dict[curr_epitope]\n",
    "        \n",
    "        # now load the saved model, from (tempoarary) file, into notebook\n",
    "        loaded_model = SeqClassificationModelWithProcessor.from_file(model_save_path)\n",
    "        # print('1.-'*30)\n",
    "        # print(tf.executing_eagerly())               \n",
    "    \n",
    "        # # check the model ROC is the same as before\n",
    "        preds = loaded_model.run(test_input)\n",
    "        if tf.is_tensor(preds):\n",
    "            preds = preds.numpy()\n",
    "        \n",
    "        # threshold = DeepAIR_BRP_cutoff_point_dict[curr_epitope]\n",
    "        # y_test = map_probability_to_prediction(preds, threshold)\n",
    "        \n",
    "        output_df[curr_epitope+'_prob'] = preds\n",
    "        if not label_column_name:\n",
    "            if 'labels' in list(input_df.columns):\n",
    "                output_df['Label'] = input_df['labels']\n",
    "                y_test = input_df['labels'].to_numpy()\n",
    "                calculate_performance(y_test, preds, output_folder, curr_epitope, output_per_note)\n",
    "        else:\n",
    "            output_df['Label'] = input_df[label_column_name]\n",
    "            y_test = input_df[label_column_name].to_numpy()\n",
    "            calculate_performance(y_test, preds, output_folder, curr_epitope, output_per_note)\n",
    "\n",
    "    output_df.to_csv(os.path.join(output_folder,'prediction_results.csv'))\n",
    "    \n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c254ca-d891-4466-82be-d2153f126591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(data_ori):\n",
    "    data=pd.read_csv(data_ori)\n",
    "    #'CDR3.beta', 'antigen_epitope','mhc.a','label','negative.source','license'\n",
    "    data.rename(columns={'CDR3A':'TRA_cdr3','CDR3B':'TRB_cdr3','TRAV':'TRA_v_gene','TRBV':'TRB_v_gene', 'TRAJ':'TRA_j_gene','TRBJ':'TRB_j_gene', \n",
    "                         'LongA':'a_aaseq', 'LongB':'b_aaseq','Affinity':'y_true'},inplace=True)\n",
    "    \n",
    "    data['ID']=list(range(len(data)))\n",
    "\n",
    "    df=data[['ID','TRA_cdr3','TRB_cdr3','TRA_v_gene','TRB_v_gene','TRA_j_gene','TRB_j_gene','a_aaseq','b_aaseq','Epitope','y_true']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def Model_retraining(epitope,data_path,AF2_feature_folder):\n",
    "    # epitope='A0301_KLGGALQAK_IE-1_CMV', #'Select an interested epitope'\n",
    "    input_data_file=data_path#\n",
    "    result_folder=f'./results/{epitope}'#\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "    \n",
    "    # AF2_feature_folder=f'./preprocessing_structure_feature/out_folder_step3/'\n",
    "    transformer_model_folder='./ProtTrans/prot_bert_bfd'\n",
    "    \n",
    "    mode='combined'#help='seq_only, stru_only, combined'\n",
    "    predictor_info='GatedFusion'#help='CNN, GatedFusion'\n",
    "    SeqEncoderTrans=True#help='transformer encoder'\n",
    "    AF2_Info='Feature' #help='3D_structure, Feature'\n",
    "    label_column_name=None\n",
    "    dataset_name='unseen'\n",
    "    model_seed=42\n",
    "\n",
    "    \n",
    "    # setting network seeds\n",
    "    model_seed_set(model_seed = model_seed)\n",
    "\n",
    "    # seq_transformer_info\n",
    "    if SeqEncoderTrans:\n",
    "        #---------------------------------------------------#\n",
    "        transformer_tokenizer_name = os.path.abspath(transformer_model_folder)\n",
    "        transformer_model_name = os.path.abspath(transformer_model_folder)    \n",
    "        transformer_tokenizer = BertTokenizer.from_pretrained(transformer_tokenizer_name, do_lower_case=False)\n",
    "        SeqInforModel = TFBertModel.from_pretrained(transformer_model_name, from_pt=False)\n",
    "        SeqInforModel.trainable = False\n",
    "        #---------------------------------------------------#    \n",
    "    else:\n",
    "        transformer_tokenizer = None\n",
    "        SeqInforModel = None\n",
    "    \n",
    "    seq_transformer_info = dict()\n",
    "    seq_transformer_info['whether_use_transformer'] = SeqEncoderTrans\n",
    "    seq_transformer_info['tokenizer'] = transformer_tokenizer\n",
    "    seq_transformer_info['tokenizer_fea_len'] = 40\n",
    "    seq_transformer_info['SeqInforModel'] = SeqInforModel\n",
    "    seq_transformer_info['transformer_feature'] = 'pooler_output' # 'pooler_output', 'last_hidden_state'\n",
    "    seq_transformer_info['Transformer_fea_len'] = 1024\n",
    "\n",
    "    if AF2_Info == 'Feature':\n",
    "        # AF2 Features\n",
    "        AF2_Feature_Info = dict()\n",
    "        AF2_Feature_Info['seq_max_len'] = 40\n",
    "        AF2_Feature_Info['fea_dim'] = 384\n",
    "        AF2_Feature_Info['feature_file'] = AF2_feature_folder\n",
    "    else:\n",
    "        AF2_Feature_Info = None\n",
    "        \n",
    "    if not isinstance (epitope, list):\n",
    "        selected_epitope = [epitope]\n",
    "    else:\n",
    "        selected_epitope = epitope\n",
    "        \n",
    "    print('-'*30)\n",
    "    print(selected_epitope)    \n",
    "    output_value = predict(input_data_file, \n",
    "                            transformer_model_folder, \n",
    "                            seq_transformer_info, # encoder sequence\n",
    "                            AF2_Feature_Info, # encoder structure\n",
    "                            selected_epitope = selected_epitope,\n",
    "                            output_folder= result_folder,\n",
    "                            label_column_name = label_column_name,\n",
    "                            task_name = dataset_name\n",
    "                        ) #'TRB_v_gene','TRB_j_gene','TRA_v_gene','TRA_j_gene','TRB_cdr3','TRA_cdr3',\n",
    "\n",
    "def aggregate_results(testfile,epi_list, savedir, result_path):\n",
    "    y_pred=[];epi_ls=[]\n",
    "    df_results=pd.DataFrame()\n",
    "    for epitope in epi_list:\n",
    "        data_path=f'{savedir}{epitope}.csv'\n",
    "        df_epi=pd.read_csv(data_path)\n",
    "        df_results=pd.concat([df_results,df_epi],axis=0)\n",
    "        result_folder=f'./results/{epitope}/'\n",
    "        df_pre=pd.read_csv(result_folder+'prediction_results.csv')\n",
    "        y_pred.extend(df_pre[df_pre.columns[-1]].tolist())\n",
    "        epi_ls.extend([epitope]*len(df_epi))\n",
    "    df_results['Epi']=epi_ls\n",
    "    df_tmp=pd.read_csv(testfile)\n",
    "    for i in range(len(df_tmp)):\n",
    "        df_results.loc[(df_results.TRB_cdr3==df_tmp['CDR3B'][i])&(df_results.TRA_cdr3==df_tmp['CDR3A'][i]),'y_true']=df_tmp['Affinity'][i]\n",
    "    df_results['y_prob']=y_pred\n",
    "    df_results['y_pred'] = df_results['y_prob'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    df_results.to_csv(result_path+'probability1.csv', index=False)\n",
    "    print(\"Saving done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a111762-3c57-4770-8309-762d4b66d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile_path=\"../../data/train_CDR3B_others.csv\"\n",
    "result_path=\"../../result_path/Retraining_model_prediction\"\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "AF2_feature_folder= f'./preprocessing_structure_feature/out_folder_step3/' \n",
    "df_test=fix(testfile_path)\n",
    "epi_list=df_test.Epitope.unique().tolist()\n",
    "savedir = \"../tmp_results/\"\n",
    "os.makedirs(savedir, exist_ok=True)\n",
    "for epitope in epi_list:\n",
    "    print('epitope:',epitope)\n",
    "    df_epi=df_test.loc[df_test.Epitope==epitope]               \n",
    "    data_path=f'{savedir}{epitope}.csv'\n",
    "    df_epi.to_csv(data_path, index=False)\n",
    "    Model_retraining(epitope,data_path, AF2_feature_folder)\n",
    "aggregate_results(testfile_path, epi_list, savedir, result_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04564f9-6f62-401f-8010-f5c0547b00a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCREpi(mcmc)",
   "language": "python",
   "name": "mcmc1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
